# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hevx2fOAhjqjW5JM4qYliQ4skxGceSu_
"""

!pip install keras-tuner

import tensorflow as tf
from tensorflow import keras
import numpy as np

print(tf.__version__)

fashion_mnist=keras.datasets.fashion_mnist

(train_images,train_labels),(test_images,test_labels)=fashion_mnist.load_data()

# Scaling down images

train_images=train_images/255
test_images=test_images/255

train_images[0].shape

#transforimg the images from 3 dimensions to 4 dimensions

train_images=train_images.reshape(len(train_images),28,28,1)
test_images=test_images.reshape(len(test_images),28,28,1)

from tensorflow.keras.models import Sequential

def build_model(hp):  
  model = keras.Sequential([
    keras.layers.Conv2D(
        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),
        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),
        activation='relu',
        input_shape=(28,28,1)
    ),
    keras.layers.Conv2D(
        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),
        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),
        activation='relu'
    ),
    keras.layers.Flatten(),
    keras.layers.Dense(
        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),
        activation='relu'
    ),
    keras.layers.Dense(10, activation='softmax')
  ])
  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
  return model

""" **Using the keras.sequential we build a sequential layer by adding convolutional 2D layer using the function 'keras.layers.conv2D' and now we add filters by performing hyperparameter tuning by using the hp.Int function which chooses a range of values between 32 and 512 with step size as 16. Kernel size is the filter size and activation function is Relu with input dimension as 28*28*1 and there 60000 such images. hp is the alias for hyper parameter class.Now whatever the filter size we apply we get the output matrix of some dimension. By using keras.layers.flatten() we will convert this to a vector of 1 dimension and again using a hyperparameter tuning connecting these to nodes with no. of nodes ranging between 32 to 512 and step size as 16. Now that we have created nodes we connect this to an output layer with 10 class and the activation is softmax which will convert the output into its probabilities.**"""

from kerastuner import RandomSearch
from kerastuner.engine.hyperparameters import HyperParameters

tuner_search=RandomSearch(build_model,objective='val_accuracy',max_trials=5,directory='output',project_name="Mnist_Fashion")

tuner_search.search(train_images,train_labels,epochs=3,validation_split=0.1)

